#!/usr/bin/env python

import argparse
import json
import re


parser = argparse.ArgumentParser()
parser.add_argument(
    "--output_filepath",
    help="Path to output file",
    default="output/asist_output.txt",
    nargs="?"
)
parser.add_argument(
    "--glove_file",
    help="Path to Glove file",
    default="data/glove.short.300d.punct.txt",
    nargs="?"
)
parser.add_argument(
    "--emotion_model",
    help="Path to saved model you would like to use in testing",
    default="data/EMOTION_MODEL_FOR_ASIST_batch100_100hidden_2lyrs_lr0.01.pth",
    nargs="?"
)
parser.add_argument(
    "--config_path",
    help="Path to config file you would like to use for testing; expects file named config.py",
    default="tomcat_speech/train_and_test_models/testing_parameters/",
    nargs="?"
)
# parser.add_argument(
#     "--input_utterance_json",
#     help="Input json file with utterance- and word-level data to get predictions on",
#     nargs="+"
# )
parser.add_argument(
    "--input_aligned_json",
    help="Input json file(s) to get predictions on",
    nargs="+"
)

args = parser.parse_args()


def decode_stacked(document, pos=0, decoder=json.JSONDecoder()):
    """
    Decode stacked json messages within a single file
    Adapted from: https://stackoverflow.com/questions/27907633/how-to-extract-multiple-json-objects-from-one-file/50384432
    """
    start_of_json = re.compile(r'[\S]')
    doc = document.read()
    while True:
        match = start_of_json.search(doc, pos)
        if not match:
            return
        pos = match.start()

        try:
            obj, pos = decoder.raw_decode(doc, pos)
        except json.JSONDecodeError as e:
            ex = e
            break
        else:
            ex = None
            yield obj

    if ex is not None:
        raise ex


if __name__ == "__main__":
    import random
    import json
    import re
    import numpy as np
    import torch
    import sys
    from tomcat_speech.data_prep.asist_data.asist_dataset_creation import (
        AsistDataset,
    )
    from tomcat_speech.models.train_and_test_models import (
        multitask_predict_without_gold_labels
    )
    from tomcat_speech.models.input_models import (
        MultitaskModel
    )

    from tomcat_speech.data_prep.data_prep_helpers import (
        make_glove_dict,
        Glove,
        DatumListDataset,
    )

    # Import parameters for model
    # import tomcat_speech.train_and_test_models.testing_parameters.config as params
    import pandas as pd

    # import config file by adding its path
    sys.path.append(args.config_path)
    import config as params


    # Set device, checking CUDA
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # set random seed
    seed = params.model_params.seed
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

    # set number of splits
    num_splits = 1

    # set model name and model type
    model = params.model_params.model

    # decide if you want to use avgd feats
    avgd_acoustic = params.model_params.avgd_acoustic or params.model_params.add_avging

    # add speaker and utterance to acoustic features extracted
    acoustic_dict_cols = params.acoustic_columns
    acoustic_dict_cols[:0] = ["speaker", "utt", "timestart"]

    # create the acoustic dict
    acoustic_dict = {}
    # create utts dict for metadata
    utts_dict = {}

    # for file in files (in case more than one)
    for json_file in args.input_aligned_json:

        # open the file with multiple jsons
        with open(json_file, 'r') as j_file:
            # get the data from all jsons in this file
            all_jsons = decode_stacked(j_file)

            # for each utterance
            for utt_json in all_jsons:
                # get the text, speaker id, utt id, and start time
                utterance = utt_json["data"]["text"]
                speaker = utt_json["data"]["id"]
                utt_id = utt_json["data"]["utterance_id"]
                start_time = utt_json["data"]["word_messages"][0]["start_time"]

                # create features var
                utt_feats = None

                # iterate through utterance, get acoustic feats
                for wd_message in utt_json["data"]["word_messages"]:
                    # todo: if we ever want to split by word (e.g. for wd-level RNN)
                    #   add that possibility here
                    try:
                        if utt_feats is None:
                            utt_feats = pd.DataFrame.from_dict(eval(wd_message["features"]))
                        else:
                            # get the acoustic info
                            item_feats = pd.DataFrame.from_dict(eval(wd_message["features"]))
                            utt_feats = pd.concat([utt_feats, item_feats], ignore_index=True)
                    # sometimes the features data is null
                    # in these cases, just skip this data
                    except NameError:
                        continue
                # average acoustic feats, if required
                if avgd_acoustic:
                    utt_feats = pd.DataFrame(utt_feats.mean(axis=0)).transpose()

                # add metadata to utts dict
                utts_dict[utt_id] = {"speaker": speaker, "utt": utterance, "timestart": start_time,
                                     "msg": utt_json["msg"]}

                # add acoustic data to acoustic dict
                acoustic_dict[utt_id] = utt_feats
                acoustic_dict[utt_id]["speaker"] = speaker
                acoustic_dict[utt_id]["utt"] = utterance
                acoustic_dict[utt_id]["timestart"] = start_time

    print("Acoustic dict created")

    # 2. IMPORT GLOVE + MAKE GLOVE OBJECT
    glove_dict = make_glove_dict(args.glove_file)
    glove = Glove(glove_dict)
    print("Glove object created")

    # 3. MAKE DATASET
    data = AsistDataset(
        acoustic_dict,
        glove,
        splits=1,
        sequence_prep="pad",
        truncate_from="start",
        norm=None,
        add_avging=params.model_params.add_avging,
        transcript_type="zoom"
    )

    # get data for testing
    test_data = data.current_split
    test_ds = DatumListDataset(test_data, None)

    # 6. CREATE NN
    # get set of pretrained embeddings and their shape
    pretrained_embeddings = glove.data
    num_embeddings = pretrained_embeddings.size()[0]
    print(f"shape of pretrained embeddings is: {data.glove.data.size()}")

    # create test model
    classifier = MultitaskModel(
        params=params.model_params,
        num_embeddings=num_embeddings,
        pretrained_embeddings=pretrained_embeddings,
        multi_dataset=False
    )
    # get saved parameters
    classifier.load_state_dict(torch.load(args.emotion_model))
    classifier.to(device)
    # test the model
    ordered_predictions = multitask_predict_without_gold_labels(
        classifier,
        test_ds,
        params.model_params.batch_size,
        device,
        num_predictions=2,
        avgd_acoustic=avgd_acoustic,
        use_speaker=params.model_params.use_speaker,
        use_gender=params.model_params.use_gender,
        get_prob_dist=True
    )

    print(ordered_predictions)

    # dict for printing emotions associated with model predictions:
    emotions = {
        "0" : "anger",
        "1" : "disgust",
        "2" : "fear",
        "3" : "joy",
        "4" : "neutral",
        "5" : "sadness",
        "6" : "surprise"
    }

    traits = {
        "0" : "extroversion",
        "1" : "neuroticism",
        "2" : "agreeableness",
        "3" : "openness",
        "4" : "conscientiousness"
    }

    # subset of the full dataset for the final output. Here, all rows from all datasets are combined,
    # just like the dataset with the predictions:

    def printdict(nm, directory):
        df1 = pd.DataFrame()
        for item in directory:
            file = [str(item)]
            nm.extend(file)
            y = directory[item] #this is a pandas dataframe
            # y["Filename"] = file
            sub = y[["speaker", "utt", "timestart"]].copy(deep=False)
            sub.insert(0, "filename", str(item))
            df1 = pd.concat([df1, sub])
        return df1

    def get_metadata(input_json):
        # get the input from utterance json
        # version
        version = input_json['msg']['version']
        # experiment id
        exp_id = input_json['msg']['experiment_id']

        return version, exp_id

    g = []
    df = printdict(g, acoustic_dict)
    # add columns with predictions to dataframe:
    df["model_prediction_emotion"] = [i[0] for i in ordered_predictions[0]]
    df["confidence_level_emotion"] = [i[1] for i in ordered_predictions[0]]
    df["model_prediction_personality"] = [i[0] for i in ordered_predictions[1]]
    df["confidence_level_personality"] = [i[1] for i in ordered_predictions[1]]
    # Final output:
    output_dict = {}
    with open(args.output_filepath, "w") as f:
        for index, row in df.iterrows():
            vers, exp = get_metadata(utts_dict[row["filename"]])
            output_dict = {
                "header": {
                    "timestamp": row["timestart"],
                    # "timestamp": "some_time_stamp",
                    "message_type": "event",
                    "version": vers
                    },
                "msg": {
                    "source": "TomcatSpeechAnalyzer",
                    "experiment_id": exp,
                    "timestamp": row["timestart"],
                    "sub_type": "Event:speech_feature",
                    "version": vers,
                    "filename": row["filename"]
                },
                "data":
                        {
                        "speaker": row["speaker"],
                        "utterance": row["utt"],
                        "emotion_detected": emotions[str(row["model_prediction_emotion"])],
                        "emotion_confidence_level": row["confidence_level_emotion"],
                        "dominant_trait_detected": traits[str(row["model_prediction_personality"])],
                        "trait_confidence_level": row["confidence_level_personality"]
                        }
                    }
            f.write(json.dumps(output_dict) + "\n")
